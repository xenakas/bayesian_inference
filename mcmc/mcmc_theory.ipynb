{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Bayesian Modelling and Markov chain Monte Carlo](https://manchestersiam.wordpress.com/2016/04/18/bayesian-modelling-and-markov-chain-monte-carlo/)\n",
    "\n",
    "Bayesian method provides an intuitive way for us to fill the gaps left by small or incomplete data sets. \n",
    "\n",
    "\n",
    "To calculate the Bayesian predictive distribution, $\\pi(x|D)$, given some data $D$,  we simply multiply the density function of the classical solution  $\\ell (D|x)$,  with the density function produced by our prior knowledge $\\pi(x)$. This is a direct application of Bayes’ theorem. Unfortunately, this product will not integrate to one. To overcome this, we multiply the density function by a constant $Z$, which rescales the density so that it does integrate to one. The resulting Bayesian distribution defined over the n-dimensional parameter space $S$ is\n",
    "\n",
    "$$ \\pi(x|D) = \\frac{1}{Z} \\pi(x) \\ell(D|x)$$\n",
    "\n",
    "$$ Z = \\int_S \\pi(x) \\ell(D|x) dx$$\n",
    "\n",
    "In one dimension it is easy to use numerical quadrature to calculate $Z$. However as the dimension becomes large, this method quickly becomes impractical. So we turn to a class of statistical algorithms known as Markov chain Monte Carlo (MCMC) methods, which can tackle these high dimensional parameter spaces.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [MCMC for hierarchical models](http://www.math.chalmers.se/~bodavid/GMRF2015/Lectures/F6slides.pdf)\n",
    "\n",
    "Classes of hierarchical [GMRF models](http://www.math.chalmers.se/~bodavid/GMRF2015/) \n",
    "\n",
    "We can divide these models into three classes with increasing\n",
    "difficulty in terms of estimation\n",
    "\n",
    "1. Normal data\n",
    "2. Non-normal data that allows for a normal-mixture representation (Student-t distribution, Logistic and Laplace (Binary regression))\n",
    "3. Non-normal data (Poisson) \n",
    "\n",
    "Mathematically, we usually want to know about two things:\n",
    "$$π(x_i|y) ∝ \\int_{x){−i}}\\int_θ π(y|x, θ)π(x|θ)π(θ) dθ dx_{−i} \\\\\n",
    " π(θ_i|y) ∝ \\int_x \\int_{θ_{−i}} π(y|x, θ)π(x|θ)π(θ) dθ_{−i} dx $$\n",
    "These are very high dimensional integrals and are not typically\n",
    "analytically tractable.\n",
    "\n",
    "Monte Carlo integration: \n",
    "$$\\int_{R^d} f(x)π(x) dx ≈ 1/N \\sum^N_{i=1} f(x_i)$$ \n",
    "where $x_i$ are drawn randomly from a distribution with pdf $π(x)$.\n",
    "\n",
    "The idea is that if we can sample from $π(x, θ|y)$ then we can do all\n",
    "the required Bayesian computations.\n",
    "One small problem: We can’t!\n",
    "\n",
    "It turns out that we don’t need to sample from $π(x, θ|y)$ directly\n",
    "to make Monte Carlo methods work.\n",
    "It’s enough to construct a Markov Chain that has $π(x, θ|y)$ as a\n",
    "stationary distribution.\n",
    "It turns out that this is easy to do. But it is hard to do well.\n",
    "\n",
    "#### Markov Chain Monte Carlo\n",
    "\n",
    "To construct a Markov chain with stationary distribution, $π(x)$:\n",
    "- Start with a proposal kernel, $q(x, y)$, and accept the proposed jumps with probability $α(x, y)$.\n",
    "- The resulting combined proposal kernel is given by\n",
    "$$\\tilde{q}(x, y) = α(x, y)q(x, y) + \\left( 1 − \\int_X α(x, z)q(x, z)dz \\right) δ_x(y)$$\n",
    "- We now want an $α(x, y)$ that gives detailed balance for the combined Markov chain, \n",
    "$$π(x)\\tilde{q}(x, y) = π(y)\\tilde{q}(y, x)$$\n",
    "Because this ensures that $π(x)$ is a stationary distribution.\n",
    "- Choose\n",
    "$α(x, y) = min \\left( 1, \\frac{π(y)q(y, x)}{π(x)q(x, y)}\\right)$\n",
    "\n",
    "Depending on the specific choice of the proposal kernel $q(θ^∗ |θ)$,\n",
    "very different algorithms result.\n",
    "- When $q(θ^∗|θ)$ does not depend on the current value of $θ$ proposal is called an independence proposal.\n",
    "- When $q(θ^∗|θ) = q(θ|θ^∗)$ we have a Metropolis proposal. These includes so-called random-walk proposals.\n",
    "\n",
    "The rate of convergence toward $π(θ)$\n",
    "and the degree of dependence\n",
    "between successive samples of the Markov chain (mixing) will\n",
    "depend on the chosen proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Metropolis Hastings algorithm\n",
    "\n",
    "Given a density $π(x)$ and a proposal kernel $q(x, y)$. \n",
    "Start the chain with some $x^{(0)}$, and loop over $t = 1, . . . , T$.\n",
    "1. Given $x^{(t)}$, draw a proposal y from $q(x^{(t)}, y)$.\n",
    "2. Calculate the acceptance probability\n",
    "$$α(x^{(t)}, y) = min \\left( 1, \\frac{π(y)q(y, x^{(t)})}{π(x^{(t)})q(x^{(t)}, y) }\\right)$$\n",
    "3. With probability $α(x^{(t)}, y)$ accept the proposal, otherwise keep\n",
    "the old value, $x^{(t)}$:\n",
    "    - Draw $u ∈ U(0, 1)$\n",
    "    - Take \n",
    "    $$x^{(t+1)} =  \\begin{cases}     \n",
    "y, \\ if \\  u < α(x^{(t)}, y) \\\\\n",
    "x^{(t)}, \\  if \\  u ≥ α(x^{(t)}, y)\n",
    "       \\end{cases}$$\n",
    "    \n",
    "##### Ensuring convergence\n",
    "The following are sufficient requirements for convergence of the\n",
    "Markov chain:\n",
    "\n",
    "1. Detailed balance (by construction).\n",
    "2. Irreducible chain: The chain should be able to reach any point $\\{x : π(x) \\neq 0\\}$ regardless of the starting point.\n",
    "3. Aperiodic chain: The existence of a unique stationary distribution is ensured by 1. and 2.; aperiodic chain is needed to ensure convergence. \n",
    "\n",
    "If the above requirements are fulfilled, then for any set $A ⊆ X$,\n",
    "$$P(X^{(t)} ∈ A) → \\int_A π(x)dx, t → ∞$$,\n",
    "independently of starting point, $x^{(0)}$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Gibbs sampling algorithm\n",
    "\n",
    "The idea in Gibbs sampling is to construct a Markov chain by\n",
    "sampling from the simpler conditional distributions.\n",
    "\n",
    "1. Choose a starting value $ θ^{(0)} $\n",
    "2. Repeat for $i = 1, . . . , N:$\n",
    "    - Draw $θ^{(i)}_1$ from $π(θ_1|θ^{(i−1)}_2, . . . , θ^{(i−1)}_m )$\n",
    "    - Draw $θ^{(i)}_2$ from $π(θ_2|θ^{(i)}_1, θ^{(i−1)}_3, . . . ,θ^{(i−1)}_m )$\n",
    "    - Draw $θ^{(i)}_3$ from $π(θ_3|θ^{(i)}_1, θ^{(i)}_2, θ^{(i−1)}_4, . . . , θ^{(i−1)}_m )$\n",
    "    - ...\n",
    "    - Draw $θ^{(i)}_m$ from $π(θ_m|θ^{(i)}_1, θ^{(i)}_2, . . . , θ^{(i)}_{m−1})$\n",
    "3. $θ^{(1)}, θ^{(2)}, . . . , θ^{(N)}$, is now a sequence of dependent draws approximately from π.\n",
    "\n",
    "The chain is not reversible if the variables are sampled cyclically:\n",
    "- This may cause problems with slow convergence.\n",
    "- Sample using a random order or using a backward forward scheme.\n",
    "\n",
    "#### Key lesson:The first rule of Bayes club.\n",
    "There is no reason to separate “fixed” and “random”\n",
    "effects in Bayesian models: __They just have different priors__\n",
    "- This implies that (Gaussian) fixed and random effects should be treated together in any inference method.\n",
    "- The general procedure is to find all of the (jointly) Gaussian bits of your model and block!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Monte Carlo integration](https://people.csail.mit.edu/mrub/talks/filtering.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate complex integrals using probabilistic\n",
    "techniques\n",
    "\n",
    "Assume we are trying to estimate a\n",
    "complicated integral of a function $f$ over some\n",
    "domain $D$ and there exists some PDF $p$ defined\n",
    "over $D$:\n",
    "$$F = \\int_D f(\\vec{ x}) d \\vec{x} $$\n",
    "\n",
    "Then\n",
    "$$ F = \\int_D f(\\vec{ x}) d \\vec{x} = \\int_D \\frac{f(\\vec{ x})}{p(\\vec{ x})} p(\\vec{ x}) d\\vec{ x}= E\\left[ \\frac{f(\\vec{ x})}{p(\\vec{ x})} \\right] $$ \n",
    "\n",
    "If we have i.i.d random samples $\\vec{ x}_1,\\dots,\\vec{ x}_N$ \n",
    "sampled from p, then we can approximate  $F$ by:\n",
    "$$ F_N =1/N \\sum^N_{i=1} \\frac{f(\\vec{ x}_i)}{p(\\vec{ x}_i)} $$\n",
    "\n",
    "Guaranteed by law of large numbers:\n",
    "$$N\\to \\infty, F_N \\xrightarrow{d}  E\\left[ \\frac{f(\\vec{ x})}{p(\\vec{ x})}\\right] =F $$ \n",
    "\n",
    "#### Convergence of MC integration\n",
    "\n",
    "Chebyshev’s inequality: \n",
    "$$\\Pr \\{ |X-\\mu| \\geq k\\sigma \\} \\leq \\frac{1}{k^2}, \\forall k>0 \\in R^d$$\n",
    "\n",
    "Let     $y_i = \\frac{f(\\vec{ x})}{p(\\vec{ x})} $           ,  then MC estimator is $ F_N =1/N \\sum^N_{i=1} y_i  $\n",
    "\n",
    "\n",
    "By Chebyshev’s:\n",
    "$$ \\Pr \\left\\{ |F_N-E[F_N]  \\geq \\left( \\frac{Var[F_N]}{\\delta}\\right)^{1/2} \\right\\} \\leq \\delta, \\ \\  k = 1/\\sqrt{\\delta}  \\\\\n",
    "\\Pr \\left\\{ |F_N-F | \\geq \\frac{1}{\\sqrt{N}}\\left(\\frac{Var[y]}{\\delta}\\right)^{1/2} \\right\\} \\leq \\delta$$\n",
    "\n",
    "Hence, for a fixed threshold, the error decreases\n",
    "at rate $1/\\sqrt{ N}$\n",
    "\n",
    "Meaning\n",
    "1. To cut the error in half, it is necessary to evaluate 4 times as many samples\n",
    "2. Convergence rate is independent of the integrand dimension (on contrast, the convergence rate of grid‐based approximations  decreases as         $N_x$ increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
